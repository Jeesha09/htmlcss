{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "version_major": 2,
        "version_minor": 0,
        "state": {}
      }
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Pandas utility functions",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.isnull(np.nan)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.isnull(None)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.isna(np.nan)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.isna(None)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.notnull(None)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.notnull(np.nan)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.notna(np.nan)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.notnull(3)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### These functions also work with Series and DataFrames:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.isnull(pd.Series([1, np.nan, 7]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.notnull(pd.Series([1, np.nan, 7]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.isnull(pd.DataFrame({\n    'Column A': [1, np.nan, 7],\n    'Column B': [np.nan, 2, 3],\n    'Column C': [np.nan, 2, np.nan]\n}))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Pandas Operations with Missing Values\n#### Pandas manages missing values more gracefully than numpy. nans will no longer behave as \"viruses\", and operations will just ignore them completely:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.Series([1, 2, np.nan]).count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.Series([1, 2, np.nan]).sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.Series([2, 2, np.nan]).mean()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Filtering missing data\n#### As we saw with numpy, we could combine boolean selection + pd.isnull to filter out those nans and null values",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s = pd.Series([1, 2, 3, np.nan, np.nan, 4])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.notnull(s)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.isnull(s)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.notnull(s).sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.isnull(s).sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s[pd.notnull(s)]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### But both notnull and isnull are also methods of Series and DataFrames, so we could use it that way:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s.isnull()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.notnull()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s[s.notnull()]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Dropping null values\n##### Boolean selection + notnull() seems a little bit verbose and repetitive. And as we said before: any repetitive task will probably have a better, more DRY way. In this case, we can use the dropna method:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.dropna()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Dropping null values on DataFrames\n#### You saw how simple it is to drop nas with a Series. But with DataFrames, there will be a few more things to consider, because you can't drop single values. You can only drop entire columns or rows. Let's start with a sample DataFrame:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.DataFrame({\n    'Column A': [1, np.nan, 30, np.nan],\n    'Column B': [2, 8, 31, np.nan],\n    'Column C': [np.nan, 9, 32, 100],\n    'Column D': [5, 8, 34, 110],\n})",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.info()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.isnull()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.isnull().sum()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.dropna()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### In this case we're dropping rows. Rows containing null values are dropped from the DF. You can also use the axis parameter to drop columns containing null values:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.dropna(axis=1)  # axis='columns' also works",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### In this case, any row or column that contains at least one null value will be dropped. Which can be, depending on the case, too extreme. You can control this behavior with the how parameter. Can be either 'any' or 'all':",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df2 = pd.DataFrame({\n    'Column A': [1, np.nan, 30],\n    'Column B': [2, np.nan, 31],\n    'Column C': [np.nan, np.nan, 100]\n})",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.dropna(how='all')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.dropna(how='any')  # default behavior",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### You can also use the thresh parameter to indicate a threshold (a minimum number) of non-null values for the row/column to be kept",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.dropna(thresh=3)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.dropna(thresh=3, axis='columns')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "# Filling null values\n#### Sometimes instead than dropping the null values, we might need to replace them with some other value. This highly depends on your context and the dataset you're currently working. Sometimes a nan can be replaced with a 0, sometimes it can be replaced with the mean of the sample, and some other times you can take the closest value.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.fillna(0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.fillna(s.mean())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Filling nulls with contiguous (close) values\n\n#### The method argument is used to fill null values with other values close to that null one:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s.fillna(method='ffill')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.fillna(method='bfill')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### This can still leave null values at the extremes of the Series/DataFrame:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.Series([np.nan, 3, np.nan, 9]).fillna(method='ffill')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.Series([1, np.nan, 3, np.nan, np.nan]).fillna(method='bfill')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Filling null values on DataFrames\n#### The fillna method also works on DataFrames, and it works similarly. The main differences are that you can specify the axis (as usual, rows or columns) to use to fill the values (specially for methods) and that you have more control on the values passed:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.fillna({'Column A': 0, 'Column B': 99, 'Column C': df['Column C'].mean()})",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.fillna(method='ffill', axis=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df.fillna(method='ffill', axis=1)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Checking if there are NAs\n#### The question is: Does this Series or DataFrame contain any missing value? The answer should be yes or no: True or False. How can you verify it?\n\n### Example 1: Checking the length\n\n#### If there are missing values, s.dropna() will have less elements than s:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s.dropna().count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "missing_values = len(s.dropna()) != len(s)\nmissing_values",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### There's also a count method, that excludes nans from its result:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "len(s)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.count()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### So we could just do:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "missing_values = s.count() != len(s)\nmissing_values",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### More Pythonic solution any\n\n#### The methods any and all check if either there's any True value in a Series or all the values are True. They work in the same way as in Python:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.Series([True, False, False]).any()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.Series([True, False, False]).all()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.Series([True, True, True]).all()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### The isnull() method returned a Boolean Series with True values wherever there was a nan:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "s.isnull()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### So we can just use the any method with the boolean array returned:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pd.Series([1, np.nan]).isnull().any()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "pd.Series([1, 2]).isnull().any()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.isnull().any()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.isnull().values",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "s.isnull().values.any()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}